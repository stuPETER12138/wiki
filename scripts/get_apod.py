from pathlib import Path
import argparse
from nasa_apod import apod
from openai import OpenAI
from rich import print


parser = argparse.ArgumentParser()
parser.add_argument(
    "--model_api_key",
    type=str,
    default="",
    help="ModelScope API Key",
)   
args = parser.parse_args()
MODEL_API_KEY = args.model_api_key
KEY = "DEMO_KEY"
MD_DIR = Path(__file__).parent.parent / "docs" / "explore" / "aerospace"
apod_service = apod.APODService(KEY)
picture = apod_service.get_picture()
print(picture)


# get the copyright
try:
    copyright = picture["copyright"]
except Exception:
    print("\n No Copyright! \n")
    copyright = "Not Found"
# get the title
title = picture["title"]
# get the date
date = picture["date"]
# get the explanation
explanation = ""
content_url = ""
if picture["media_type"] == "image":
    try:
        url = picture["hdurl"]
    except Exception:
        print("\n No hdurl! \n")
        url = picture["url"]
    content_url = f"\n![]({url})\n"
elif picture["media_type"] == "video":
    url = picture["url"]
    content_url = f"\n@[youtube]({url})\n"
else:
    print("\n No image or video! \n")

client = OpenAI(
    base_url="https://api-inference.modelscope.cn/v1/",
    api_key=MODEL_API_KEY,  # ModelScope Token
)

# set extra_body for thinking control
extra_body = {
    # enable thinking, set to False to disable
    "enable_thinking": True,
    # use thinking_budget to contorl num of tokens used for thinking
    # "thinking_budget": 4096
}

response = client.chat.completions.create(
    model="Qwen/Qwen3-235B-A22B-Instruct-2507",  # ModelScope Model-Id
    messages=[
        {
            "role": "system",
            "content": """ä½œä¸ºä¸“ä¸šè‹±è¯­ç¿»è¯‘å¤„ç†åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼š
# æ–‡æœ¬åˆ†æ

- è¯†åˆ«å¹¶æå–æ–‡æœ¬ä¸­çš„ä¸“ä¸šæœ¯è¯­ä»¥åŠç”Ÿåƒ»è¯æ±‡ã€CET 4 çº§åŠä»¥ä¸Šã€‘

# ç¿»è¯‘å¤„ç†

- å¯¹ç­›é€‰å‡ºçš„ç›®æ ‡è¯æ±‡è¿›è¡Œå‡†ç¡®ä¸­æ–‡ç¿»è¯‘ï¼Œæ™®é€šè¯æ±‡ä¸åšä»»ä½•å¤„ç†

- é‡‡ç”¨`è‹±æ–‡åŸè¯ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰`çš„æ ¼å¼è¿›è¡ŒåŸä½æ ‡æ³¨ï¼Œç¡®ä¿æ‹¬å·ä½¿ç”¨ä¸­æ–‡å…¨è§’æ ¼å¼ï¼ˆï¼‰ã€‚ä¾‹å¦‚ï¼šâ€œ APODï¼ˆæ¯æ—¥å¤©æ–‡ä¸€å›¾ï¼‰â€

- å½“å†æ¬¡é‡åˆ°å‰æ–‡å·²ç»ç¿»è¯‘è¿‡æŸç›®æ ‡è¯æ±‡æ—¶ï¼Œè·³è¿‡è¿™æ¬¡é‡åˆ°çš„ç›®æ ‡è¯è¯­ï¼Œä¸å†é‡å¤ç¿»è¯‘

- ä¿ç•™åŸå§‹æ–‡æœ¬çš„æ’ç‰ˆå’Œæ®µè½ç»“æ„ï¼Œä¿æŒåŸæ–‡æ ‡ç‚¹ç¬¦å·ä½“ç³»ä¸å˜

# è¾“å‡ºè¦æ±‚ï¼š

ä»…è¿”å›å¤„ç†åçš„æœ€ç»ˆæ–‡æœ¬

ç¦æ­¢æ·»åŠ è§£é‡Šè¯´æ˜

ç»´æŒåŸå§‹æ–‡æœ¬æ¢è¡Œå’Œç¼©è¿›æ ¼å¼""",
        },
        {"role": "user", "content": picture["explanation"]},
    ],
    stream=True,
    extra_body=extra_body,
)

for chunk in response:
    print(chunk.choices[0].delta.content, end='', flush=True)
    for chunk in response:
        try:
            content = chunk.choices[0].delta.content
        except Exception:
            content = None
        if content:
            print(content, end='', flush=True)
            explanation += content

# write the content to the markdown file
content = f"""# {title}

Data: {date}

Copyright: {copyright}
{content_url}
## Explanation
    
{explanation}
"""

with open(Path(MD_DIR)/"apod.md", "w", encoding="utf-8") as f:
    f.write(content)


print("\n\n ğŸ˜‹ APOD image and markdown file generated successfully! \n\n")
